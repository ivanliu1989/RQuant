% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/textMining.R
\name{text_clean}
\alias{text_clean}
\title{Function to clean your tweets text}
\usage{
text_clean(docvec, rmDuplicates = FALSE, cores = 6, stems = NULL,
  partial = FALSE)
}
\arguments{
\item{rmDuplicates}{if remove duplicated tweets}

\item{cores}{number of cores for parallel computing}

\item{stems}{customized stems to be removed}

\item{partial}{partial cleaning. step 1 to 11}

\item{tweets}{tweets retrieved from \code{tweet_corpus} function}
}
\description{
Some pre-process the data in some standard ways.
}
\details{
1. Convert to basic ASCII text to avoid silly characters\cr
2. Make everything consistently lower case\cr
3. Remove the "RT" (retweet) so duplicates are duplicates\cr
4. Remove links\cr
5. Remove punctuation\cr
6. Remove tabs\cr
7. "&" is "&amp" in HTML, so after punctuation removed ...\cr
8. Leading blanks\cr
9. Lagging blanks\cr
10. General spaces (should just do all whitespaces no?)\cr
11. Get rid of duplicates!\cr
12. Convert to tm corpus\cr
13. Remove English stop words.\cr
14. Remove numbers.\cr
15. Stem the words.\cr
16. Remove the customized stems\cr
}
\examples{
setupTwitterConn()
tweets <- tweet_corpus(search = "audusd", n = 100, since = as.character(Sys.Date()-7), until = as.character(Sys.Date()))
tweets <- text_clean(tweets$v, rmDuplicates = FALSE, cores = 6, stems = c("audusd"))

}
\seealso{
\link{tweet_corpus}
}

