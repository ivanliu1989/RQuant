% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/textMining.R
\name{tfidfTransformer}
\alias{tfidfTransformer}
\title{Generate n-grams from a document}
\usage{
tfidfTransformer(text_vector, ngrams = 1, minDocFreq = 2, wordLengths = 3,
  wordLengths_max = 20, idf = TRUE, cores = 6)
}
\arguments{
\item{text_vector}{a vector of strings to be tokenized.}

\item{ngrams}{number of grams for ngrams transformation}

\item{minDocFreq}{minimum frequency for each document to be kept}

\item{wordLengths}{minimum length of a valid word to be kept}

\item{wordLengths_max}{maximum length of a valid word to be kept}

\item{idf}{inverse-document-frequency OR term-frequency, TRUE/FALSE}

\item{cores}{number of cores for parallel computing}
}
\description{
splits strings into n-grams with given minimal and maximal numbers of grams.
}
\examples{
setupTwitterConn()
tweets <- tweet_corpus(search = "audusd", n = 100, since = as.character(Sys.Date()-7), until = as.character(Sys.Date()))
tfidf.dt =  tfidfTransformer(tweets$d$text, ngrams = 1, minDocFreq = 2, wordLengths = 3, wordLengths_max = 20, idf = TRUE, cores = 6)
head(as.matrix(tfidf.dt))

}
\seealso{
\link{tfidfTransformer}
}

